{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import json\n",
    "from renetti.ws.spiders.types import ScrapedEquipment\n",
    "from typing import List, Tuple, Optional, TypedDict, Dict\n",
    "from collections import defaultdict\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import webcolors\n",
    "import html\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prowler', 'biceps', 'sled', 'give']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lemmatizer.lemmatize(s, pos=wordnet.NOUN) for s in \"prowler biceps sleds give\".split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipment_brands = {\n",
    "    'mts',\n",
    "    \"monster lite\",\n",
    "    \"monster\",\n",
    "    \"r2\",\n",
    " 'abs company',\n",
    " 'airex',\n",
    " 'apus sports',\n",
    " 'atlantis',\n",
    " 'attack fitness',\n",
    " 'bandbell',\n",
    " 'plate loaded',\n",
    " 'bear komplex',\n",
    " 'bison designs',\n",
    " 'chalk pot',\n",
    " 'concept 2',\n",
    " 'elite iso',\n",
    " 'curve runner',\n",
    " 'cybex',\n",
    " 'drax',\n",
    " 'dynepic sports',\n",
    " 'eleiko',\n",
    " 'escape fitness',\n",
    " 'exigo',\n",
    " 'future',\n",
    " 'ghost',\n",
    " 'glutebuilderÂ®',\n",
    " 'elite commercial',\n",
    " 'goat tape',\n",
    " 'gym gear',\n",
    " 'half human',\n",
    " 'hammer strength',\n",
    " 'hatton boxing',\n",
    " 'hoist',\n",
    " 'hoist fitness',\n",
    " 'hoist lemond series',\n",
    " 'hybrid',\n",
    " 'impulse',\n",
    " 'indigo fitness',\n",
    " 'inspire fitness',\n",
    " 'home use',\n",
    " 'jacobs ladder',\n",
    " 'jerkfit',\n",
    " 'jordan',\n",
    " 'jordan fitness',\n",
    " 'kabuki strength',\n",
    " 'life fitness',\n",
    " 'lifeline usa',\n",
    " 'alpha commercial',\n",
    " 'lionheart lifting',\n",
    " 'matrix fitness',\n",
    " 'mutant metals',\n",
    " 'nautilus',\n",
    " 'noble-pro',\n",
    " 'nohrd',\n",
    " 'premium line',\n",
    " 'octane fitness',\n",
    " 'oso',\n",
    " 'per4m',\n",
    " 'physical company',\n",
    " 'pioneer',\n",
    " 'precor',\n",
    " 'primal strength',\n",
    " 'primo',\n",
    " 'proactive',\n",
    " 'pulse fitness',\n",
    " 'reebok',\n",
    " 'rogue fitness',\n",
    " 'rumbleroller',\n",
    " 'schwinn',\n",
    " 'scifit',\n",
    " 'spirit',\n",
    " \"welliv\",\n",
    " \"welliv pro\",\n",
    " 'spirit fitness',\n",
    " 'spud inc',\n",
    " 'stairmaster',\n",
    " 'star trac',\n",
    " 'stil-fit',\n",
    " 'stroops',\n",
    " 'super training products',\n",
    " 'technogym',\n",
    " 'throwdown',\n",
    " 'torque usa',\n",
    " 'true fitness',\n",
    " 'uksf',\n",
    " 'unbranded',\n",
    " 'wolverson fitness',\n",
    " 'woodway',\n",
    " 'ziva',\n",
    " \"club series\",\n",
    " \"circuit series\",\n",
    " \"club line\"\n",
    " \"prestera\",\n",
    " \"muscle\",\n",
    " \"axiom series\", \"club line\", \"dual series\", \"dual use\", \"dual series\", 'elite commercial', 'elite series', 'integrity series', 'insignia series', 'performance series', 'pro series', 'series', 'signature series', 'console', 'touch', 'screen',\n",
    " \"primal pro\", \"primal performance\", \"discover\", 'hd athletic',\n",
    " 'hd elite', 'signature', 'premium', \"indoor\", \"wall mounted\", \"inclusive\", 'plate-loaded', 'light commercial', 'iso lateral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equipment(TypedDict):\n",
    "    name: str\n",
    "    image_links: List[str]\n",
    "    mpn: Optional[List[str]]\n",
    "    description: Optional[str]\n",
    "    brands: Optional[List[str]]\n",
    "    categories: Optional[List[str]]\n",
    "    skus: Optional[List[str]]\n",
    "\n",
    "\n",
    "class NGramFrequencyProp(TypedDict):\n",
    "    one_grams: Dict[str, float]\n",
    "    two_grams: Dict[str, float]\n",
    "    three_grams: Dict[str, float]\n",
    "    four_grams: Dict[str, float]\n",
    "\n",
    "class EquipmentForAnalysis(TypedDict):\n",
    "    name: str\n",
    "    image_links: List[str]\n",
    "    mpn: Optional[List[str]]\n",
    "    description: Optional[str]\n",
    "    brands: Optional[List[str]]\n",
    "    categories: Optional[List[str]]\n",
    "    skus: Optional[List[str]]\n",
    "    one_grams: List[str]\n",
    "    two_grams: List[str]\n",
    "    three_grams: List[str]\n",
    "    four_grams: List[str]\n",
    "    n_gram_freq: Optional[NGramFrequencyProp]\n",
    "    grouping_category: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_file_paths = [\n",
    "    f\"{root}/scraped_data.json\" for root, dirs, file_paths in os.walk(\"../files\")\n",
    "][1:] # remove root file dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = set(webcolors.names() + ['graphite', 'zinc', 'color', 'colour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_number(token: str) -> bool:\n",
    "    try:\n",
    "        float(token)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_equipment_name(name: str) -> str:\n",
    "    # Decode HTML entities\n",
    "    name = html.unescape(name)\n",
    "\n",
    "    name = name.lower()\n",
    "    name = name.replace('\"', \"\").replace(\"'\", \"\")\n",
    "\n",
    "    # Remove punctuation\n",
    "    pattern = f\"[{re.escape(string.punctuation.replace(\"-\", \"\"))}]\"\n",
    "    name = re.sub(pattern, \"\", name)\n",
    "\n",
    "    # Remove weight/size units\n",
    "    pattern = r\"\\b\\d*\\s*(kg|lbs?|cm|in|mm|ft)\\b|\\b\\d+\\s*(kg|lbs?|cm|in|mm|ft)\\b\"\n",
    "    name = re.sub(pattern, \"\", name)\n",
    "\n",
    "    # Remove unwanted characters, including isolated or numeric-bound hyphens\n",
    "    name = re.sub(r\"(?<![a-zA-Z0-9])-|-(?![a-zA-Z0-9])\", \"\", name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    # Remove brand names\n",
    "    for brand in equipment_brands:\n",
    "        name = name.replace(brand.lower(), \"\")\n",
    "\n",
    "    # Tokenize, remove stop words, punctuation, colors, and numbers\n",
    "    name_tokens = name.split(\" \")\n",
    "    filtered_tokens = [\n",
    "        lemmatizer.lemmatize(token, pos=wordnet.NOUN) for token in name_tokens\n",
    "        if (\n",
    "            token not in stop_words and\n",
    "            token not in colors and\n",
    "            not is_a_number(token)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    final_name = ' '.join(filtered_tokens)\n",
    "    return final_name.replace(\" - \", \"-\").strip().replace(\"   \", \" \").replace(\"  \", \" \").replace(\"triceps\", \"tricep\").replace(\"biceps\", \"bicep\").replace('elite commercial', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello name dan give me-ppp ball hols a-a 5-stack'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_equipment_name(\n",
    "    \"'Hello my name is Dan & with that I give you me()-(ppp) red blue green graphite 2.0 999 2.1311 life fitness 10kg kg &#x2b; colour color, balls hols 8ft 20mm / a-a 5-stack \\\"/\" +\n",
    "    \"mm 25mm 25 MM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipment_data = defaultdict(list)\n",
    "equipment_data_missing_fields = defaultdict(list)\n",
    "\n",
    "for file_path in scraped_data_file_paths:\n",
    "    with open(file=file_path) as f:\n",
    "        data: List[ScrapedEquipment] = json.load(f)\n",
    "        for equipment_obj in data:\n",
    "            equipment_obj['name'] = clean_equipment_name(equipment_obj['name'])\n",
    "\n",
    "            brands = equipment_obj[\"brands\"]\n",
    "            name = equipment_obj['name']\n",
    "\n",
    "            if len(brands) != 1:\n",
    "                equipment_data_missing_fields[name.title()].append(equipment_obj)\n",
    "            else:\n",
    "                brand = brands[0]\n",
    "                unique_name = f\"({brand.title()}) {name.title()}\"\n",
    "                equipment_data[unique_name].append(equipment_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_duplicates(objs: List[ScrapedEquipment]) -> Equipment:\n",
    "    name = None\n",
    "    image_links = set()\n",
    "    mpn = set()\n",
    "    description = None\n",
    "    brands = set()\n",
    "    categories = set()\n",
    "    skus = set()\n",
    "\n",
    "    for obj in objs:\n",
    "        if name is None:\n",
    "            name = obj[\"name\"]\n",
    "\n",
    "        image_links.update(obj[\"image_links\"])\n",
    "        if obj[\"mpn\"]:\n",
    "            mpn.add(obj[\"mpn\"])\n",
    "\n",
    "        brands.update([b.lower() for b in obj[\"brands\"]] or [])\n",
    "        categories.update([c.lower() for c in obj[\"categories\"]] or [])\n",
    "        skus.update(obj[\"skus\"] or [])\n",
    "\n",
    "        if not description or (obj[\"description\"] and len(description) < len(obj[\"description\"])):\n",
    "            description = obj[\"description\"]\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'image_links': list(image_links),\n",
    "        'mpn': list(map(str.title, mpn)),\n",
    "        'description': description,\n",
    "        'brands': list(map(str.title, brands)),\n",
    "        'categories': list(map(str.title, categories)),\n",
    "        'skus': list(skus)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "dupped_equipment = {k:v for k, v in equipment_data.items() if len(v) > 1}\n",
    "print(len(dupped_equipment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_deupped_equipment = [merge_duplicates(objs=objs) for key, objs in equipment_data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../files/cleaned_scraped_equipment.json\", \"w\") as f:\n",
    "    json.dump(de_deupped_equipment, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_grams(name: str) -> Tuple:\n",
    "    tokens = name.split(\" \")\n",
    "    return [\n",
    "        list(ngrams(tokens, n=n))\n",
    "        for n in range(1, 5)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = defaultdict(lambda: defaultdict(float))\n",
    "equipments_for_analysis: List[EquipmentForAnalysis] = []\n",
    "for obj in de_deupped_equipment:\n",
    "    one_grams, two_grams, three_grams, four_grams = generate_n_grams(name=obj[\"name\"])\n",
    "    equipment_for_analysis: EquipmentForAnalysis = {\n",
    "        'name': obj['name'],\n",
    "        'image_links': obj['image_links'],\n",
    "        'mpn': obj['mpn'],\n",
    "        'description': obj['description'],\n",
    "        'brands': obj['brands'],\n",
    "        'categories': obj['categories'],\n",
    "        'skus': obj['skus'],\n",
    "        'one_grams': one_grams,\n",
    "        'two_grams': two_grams,\n",
    "        'three_grams': three_grams,\n",
    "        'four_grams': four_grams,\n",
    "    }\n",
    "    for gram in one_grams:\n",
    "        n_grams['one_grams'][gram] += 1\n",
    "    for gram in two_grams:\n",
    "        n_grams['two_grams'][gram] += 1\n",
    "    for gram in three_grams:\n",
    "        n_grams['three_grams'][gram] += 1\n",
    "    for gram in four_grams:\n",
    "        n_grams['one_grams'][gram] += 1\n",
    "    equipments_for_analysis.append(equipment_for_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for equip in equipments_for_analysis:\n",
    "    equip['n_gram_freq'] = {\n",
    "        'one_grams': {v:n_grams['one_grams'][v]/len(n_grams['one_grams']) for v in equip['one_grams']},\n",
    "        'two_grams': {v:n_grams['two_grams'][v]/len(n_grams['two_grams']) for v in equip['two_grams']},\n",
    "        'three_grams': {v:n_grams['three_grams'][v]/len(n_grams['three_grams']) for v in equip['three_grams']},\n",
    "        'four_grams': {v:n_grams['four_grams'][v]/len(n_grams['four_grams']) for v in equip['four_grams']},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003845167905665214, 0.021789284798769546)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for equip in equipments_for_analysis:\n",
    "    category = None\n",
    "\n",
    "    two_grams = equip['n_gram_freq']['two_grams']\n",
    "    three_grams = equip['n_gram_freq']['three_grams']\n",
    "    four_grams = equip['n_gram_freq']['four_grams']\n",
    "\n",
    "    for two_gram, score in two_grams.items():\n",
    "        scores.append(score)\n",
    "\n",
    "    for three_gram, score in three_grams.items():\n",
    "        scores.append(score)\n",
    "\n",
    "    for four_gram, score in four_grams.items():\n",
    "        scores.append(score)\n",
    "\n",
    "min_thres, max_thres = float(np.percentile(scores, 90)), float(np.percentile(scores, 100))\n",
    "min_thres, max_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes = []\n",
    "for equip in equipments_for_analysis:\n",
    "    category = None\n",
    "\n",
    "\n",
    "    gram_max = None\n",
    "    gram_max_score = 0\n",
    "\n",
    "    two_grams = equip['n_gram_freq']['two_grams']\n",
    "    three_grams = equip['n_gram_freq']['three_grams']\n",
    "    four_grams = equip['n_gram_freq']['four_grams']\n",
    "\n",
    "    for two_gram, score in two_grams.items():\n",
    "        if score > gram_max_score:\n",
    "            gram_max_score = score\n",
    "            gram_max = two_gram\n",
    "\n",
    "    for three_gram, score in three_grams.items():\n",
    "        if score > gram_max_score:\n",
    "            gram_max_score = score\n",
    "            gram_max = three_gram\n",
    "\n",
    "    for four_gram, score in four_grams.items():\n",
    "        if score > gram_max_score:\n",
    "            gram_max_score = score\n",
    "            gram_max = four_gram\n",
    "\n",
    "    if gram_max and gram_max_score >= min_thres:\n",
    "        maxes.append(gram_max_score)\n",
    "        equip['grouping_category'] = ' '.join(gram_max)\n",
    "    else:\n",
    "        equip['grouping_category'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3279"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([e['grouping_category'] for e in equipments_for_analysis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 'xf sled prowler heavy'), (None, 'xf sled prowler light')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(e['grouping_category'], e['name']) for e in equipments_for_analysis if 'xf sle' in e['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({e['grouping_category'] for e in equipments_for_analysis})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None,\n",
       " 'abdominal crunch',\n",
       " 'adjustable bench',\n",
       " 'adjustable pulley',\n",
       " 'back extension',\n",
       " 'barbell rack',\n",
       " 'bench press',\n",
       " 'bicep curl',\n",
       " 'bumper plate',\n",
       " 'chest press',\n",
       " 'chin dip',\n",
       " 'cross trainer',\n",
       " 'curl bar',\n",
       " 'curl bench',\n",
       " 'decline bench',\n",
       " 'dumbbell rack',\n",
       " 'ez curl',\n",
       " 'flat bench',\n",
       " 'functional trainer',\n",
       " 'half rack',\n",
       " 'hyper extension',\n",
       " 'incline bench',\n",
       " 'lat pulldown',\n",
       " 'leg curl',\n",
       " 'leg extension',\n",
       " 'leg press',\n",
       " 'low row',\n",
       " 'olympic bar',\n",
       " 'olympic bench',\n",
       " 'olympic plate',\n",
       " 'pec fly',\n",
       " 'pin select',\n",
       " 'plate storage',\n",
       " 'power rack',\n",
       " 'preacher curl',\n",
       " 'pull-up bar',\n",
       " 'rear delt',\n",
       " 'recumbent bike',\n",
       " 'seated row',\n",
       " 'shoulder press',\n",
       " 'smith machine',\n",
       " 'squat rack',\n",
       " 'squat stand',\n",
       " 'storage rack',\n",
       " 'tricep extension',\n",
       " 'upright bike'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(e['grouping_category']) for e in equipments_for_analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = defaultdict(int)\n",
    "for equip in equipments_for_analysis:\n",
    "    category[equip['grouping_category']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 2033),\n",
       " ('leg curl', 84),\n",
       " ('chest press', 77),\n",
       " ('leg press', 66),\n",
       " ('lat pulldown', 65),\n",
       " ('shoulder press', 55),\n",
       " ('dumbbell rack', 50),\n",
       " ('leg extension', 42),\n",
       " ('bicep curl', 39),\n",
       " ('functional trainer', 35),\n",
       " ('half rack', 32),\n",
       " ('flat bench', 31),\n",
       " ('olympic bar', 31),\n",
       " ('power rack', 30),\n",
       " ('bumper plate', 27),\n",
       " ('low row', 27),\n",
       " ('adjustable pulley', 27),\n",
       " ('seated row', 27),\n",
       " ('incline bench', 26),\n",
       " ('decline bench', 26),\n",
       " ('cross trainer', 26),\n",
       " ('preacher curl', 24),\n",
       " ('abdominal crunch', 24),\n",
       " ('recumbent bike', 24),\n",
       " ('pec fly', 23),\n",
       " ('olympic bench', 23),\n",
       " ('pull-up bar', 23),\n",
       " ('adjustable bench', 23),\n",
       " ('smith machine', 23),\n",
       " ('squat stand', 22),\n",
       " ('back extension', 22),\n",
       " ('upright bike', 22),\n",
       " ('chin dip', 21),\n",
       " ('tricep extension', 18),\n",
       " ('curl bar', 18),\n",
       " ('barbell rack', 15),\n",
       " ('olympic plate', 15),\n",
       " ('squat rack', 15),\n",
       " ('hyper extension', 15),\n",
       " ('storage rack', 14),\n",
       " ('plate storage', 11),\n",
       " ('pin select', 9),\n",
       " ('bench press', 8),\n",
       " ('ez curl', 5),\n",
       " ('rear delt', 4),\n",
       " ('curl bench', 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = sorted(category.items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things I could improve\n",
    "    # Single and Triple n-gram selection\n",
    "    # There's very few of these. E.g. Treadmill or \"plate loaded row\" (We did remove plate loaded but this is an example)\n",
    "    # We should come up with a mechanism of including these to improve categories later on|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renetti--Bo1TxlW-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
